{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing Libraries</h1>\n",
    "\n",
    "At first, let's import all the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as rosa\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import statistics\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting the Random Seeds</h1>\n",
    "\n",
    "When training a model, there are certain random operations that we encounter. For example, the way data is shuffled randomly when doing the training and test split, or the way weights are randomly initialized at the input of a neural network. These random operations produce different results every time we run our code. This makes it hard for us to see how much the model performance changes with changing hyperparameter values. Therefore, in order to tune the hyperparameters of a model so that we get the optimal parameter values, we set these random seeds which tells the machine to pick random values in a specific pattern. Once we finish tuning the hyperparameters, we can remove the seeds to see how the model performs for different shuffles and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds for replicating results over multiple runs.\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing Features from CSV</h1>\n",
    "\n",
    "As we have already seen in the feature extraction code, it can take a while to extract all the audio features from the audio files. Because we saved those features in a CSV file, we can directly import them in this notebook without having to go over the time-consuming process again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe/dataset into an instance/object 'df' using Pandas. Use first row as column header and first column as row header!\n",
    "df = pd.read_csv(\"C:/Users/rezwa/Documents/RAVDESS_Librosa_RNN.csv\", header=0, index_col=0)\n",
    "\n",
    "# We used 36 features. Column of dataframe represents the features (36*median_num_frames), and -1 to avoid considering column indexes.\n",
    "median_num_frames = (df.shape[1]-1)//36\n",
    "\n",
    "# Rename target labels.\n",
    "df['Emotion'].replace({\"Neutral\" : 1.0, \"Happy\" : 2.0, \"Sad\" : 3.0, \"Angry\" : 4.0, \"Fearful\" : 5.0, \"Disgust\" : 6.0, \"Surprised\" : 7.0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Balancing the Dataset</h1>\n",
    "\n",
    "One common problem in machine learning is dataset imbalance. A dataset is said to be unbalanced if all the classes do not have the same number of data samples. For our case, the RAVDESS dataset is slightly unbalanced as the neutral class has fewer number of data samples compared to the other classes. To balance our dataset so that the machine does not get biased towards the majority classes, we will *resample* examples in the minority class (i.e. neutral) until its number matches the majority class count.\n",
    "\n",
    "An important thing to note here is that we want to resample the neutral class AFTER performing the training, validation, and test splits on the neutral class. If we do it before performing the splits, the data samples resampled for the training set might end up in the validation or test set. The model will then perform really well in the testing phase and struggle in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take data samples of each class from dataframe into separate dataframes.\n",
    "df_happy = df.loc[df.Emotion==2.0]\n",
    "df_sad = df[df.Emotion==3.0]\n",
    "df_angry = df[df.Emotion==4.0]\n",
    "df_fearful = df[df.Emotion==5.0]\n",
    "df_disgust = df[df.Emotion==6.0]\n",
    "df_neutral = df[df.Emotion==1.0]\n",
    "df_surprised = df[df.Emotion==7.0]\n",
    "\n",
    "# Join only the majority classes, leaving out Neutral.\n",
    "df_maj = pd.concat([df_happy, df_sad, df_angry, df_fearful, df_disgust, df_surprised])\n",
    "\n",
    "# Extract labels of majority classes.\n",
    "y_maj = df_maj.iloc[0:1152, 36*median_num_frames].values\n",
    "# Extract features of majority classes.\n",
    "X_maj = df_maj.iloc[0:1152, list(range(36*median_num_frames))].values\n",
    "\n",
    "# Split and stratify majority class samples for training and testing.\n",
    "X_train_temp_maj, X_test_maj, y_train_temp_maj, y_test_maj = train_test_split(X_maj, y_maj, test_size=115, random_state=0, stratify=y_maj) # training split = 90%, test split = 10%\n",
    "\n",
    "# Further split and stratify majority class training samples for training data for training and validating.\n",
    "X_train_maj, X_val_maj, y_train_maj, y_val_maj = train_test_split(X_train_temp_maj, y_train_temp_maj, test_size=115, random_state=0, stratify=y_train_temp_maj) # training split = 80%, validation split = 10%\n",
    "\n",
    "# Take minority data samples from dataframe to array.\n",
    "neutral_array = df_neutral.to_numpy()\n",
    "\n",
    "# Shuffle the data samples of minority class.\n",
    "np.random.shuffle(neutral_array)\n",
    "\n",
    "# Split minority class Neutral in 80:10:10 ratio.\n",
    "train_neutral = neutral_array[0:76, :]\n",
    "val_neutral = neutral_array[76:86, :]\n",
    "test_neutral = neutral_array[86:96, :]\n",
    "\n",
    "# Resample Neutral data to match majority class samples.\n",
    "train_neutral_resampled = resample(train_neutral, n_samples=154, replace=True, random_state=0)\n",
    "val_neutral_resampled = resample(val_neutral, n_samples=19, replace=True, random_state=0)\n",
    "test_neutral_resampled = resample(test_neutral, n_samples=19, replace=True, random_state=0)\n",
    "\n",
    "# Separate features and target labels for Neutral data.\n",
    "X_train_neutral = train_neutral_resampled[:, 0:36*median_num_frames]\n",
    "X_val_neutral = val_neutral_resampled[:, 0:36*median_num_frames]\n",
    "X_test_neutral = test_neutral_resampled[:, 0:36*median_num_frames]\n",
    "y_train_neutral = train_neutral_resampled[:, 36*median_num_frames]\n",
    "y_val_neutral = val_neutral_resampled[:, 36*median_num_frames]\n",
    "y_test_neutral = test_neutral_resampled[:, 36*median_num_frames]\n",
    "\n",
    "# Join upsampled minority data samples with majority data samples.\n",
    "X_train = np.concatenate((X_train_maj, X_train_neutral), axis=0)\n",
    "X_val = np.concatenate((X_val_maj, X_val_neutral), axis=0)\n",
    "X_test = np.concatenate((X_test_maj, X_test_neutral), axis=0)\n",
    "y_train = np.concatenate((y_train_maj, y_train_neutral), axis=0)\n",
    "y_val = np.concatenate((y_val_maj, y_val_neutral), axis=0)\n",
    "y_test = np.concatenate((y_test_maj, y_test_neutral), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scaling the Features</h1>\n",
    "\n",
    "In this project, we have used four different types of features. Each of these features vary within different range of values. If we feed our features to the model in the format that we extracted them, the model will prioritize larger feature values over smaller ones. In order to avoid this numerical bias, we need to bring all the feature values into a common scale. One way to do this is standardization, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the features.\n",
    "mean_X = np.mean(X_train, axis=0)\n",
    "std_X = np.std(X_train, axis=0)\n",
    "\n",
    "# Standardize the inputs.\n",
    "X_train_centered = (X_train - mean_X)/std_X\n",
    "X_val_centered = (X_val - mean_X)/std_X\n",
    "X_test_centered = (X_test - mean_X)/std_X\n",
    "\n",
    "# Delete old variables to save space.\n",
    "del X_train, X_val, X_test, X_train_temp_maj, y_train_temp_maj\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_val_centered.shape, y_val.shape)\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>One-hot Encoding the Labels</h1>\n",
    "\n",
    "The problem with using integer encoding for our output classes is that the machine might think there is a natural ordering, or hierarchy, in the data. This can be misleading as the algorithm will adjust the weights accordingly. For avoiding this problem, we perform one-hot encoding. This creates a feature vector for the labels such that if the output is a happy label, there will be a '1' under the 'Happy' column and zeroes under all other labels for that audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encode the classes.\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "y_val_onehot = keras.utils.to_categorical(y_val)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reshaping Input Arrays</h1>\n",
    "\n",
    "In Keras, RNNs require 3D arrays (tensors) for input. The three dimensions are batch (i.e. number of data samples), timesteps, and features per timestep. We want the RNN to learn the changes of feature values with each timestep (i.e. audio frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X_train and X_test to 3D Numpy arrays for feeding into the RNN. RNNs require 3D array input.\n",
    "X_train_3D = np.reshape(X_train_centered, (X_train_centered.shape[0], median_num_frames, 36))\n",
    "X_val_3D = np.reshape(X_val_centered, (X_val_centered.shape[0], median_num_frames, 36))\n",
    "X_test_3D = np.reshape(X_test_centered, (X_test_centered.shape[0], median_num_frames, 36))\n",
    "\n",
    "print(X_train_3D.shape, y_train.shape)\n",
    "print(X_val_3D.shape, y_val.shape)\n",
    "print(X_test_3D.shape, y_test.shape)\n",
    "\n",
    "# Transpose tensors so that rows=features and columns=frames.\n",
    "X_train_3D_posed = tf.transpose(X_train_3D, perm=[0, 2, 1])\n",
    "X_val_3D_posed = tf.transpose(X_val_3D, perm=[0, 2, 1])\n",
    "X_test_3D_posed = tf.transpose(X_test_3D, perm=[0, 2, 1])\n",
    "\n",
    "print(X_train_3D_posed.shape, y_train.shape)\n",
    "print(X_val_3D_posed.shape, y_val.shape)\n",
    "print(X_test_3D_posed.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Defining RNN Architecture</h1>\n",
    "\n",
    "We will be using an LSTM network rather than a vanilla RNN as it takes care of vanishing gradient and exploding gradient problems. We will use 36 LSTM cells for our 36 features at the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object/instance 'model' for the 'Sequential()' class.\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    keras.layers.LSTM( units=36,\n",
    "                input_shape=(36, median_num_frames),\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                activation='tanh',\n",
    "                recurrent_activation='sigmoid',\n",
    "                dropout=0.30,\n",
    "                recurrent_dropout=0.30,\n",
    "                return_sequences=True))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.LSTM( units=12,\n",
    "                input_shape=(36, median_num_frames),\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                activation='tanh',\n",
    "                recurrent_activation='sigmoid',\n",
    "                dropout=0.30))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense( units=y_train_onehot.shape[1],\n",
    "                input_dim=36,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Defining the Optimizer and Loss Function</h1>\n",
    "\n",
    "We will use the Adam optimizer and the categorical crossentropy loss. We will also use a learning rate scheduler - a function that decreases the learning rate slowly as the training progresses. This will ensure that we do not overshoot the global minimum due to a high learning rate during the final stage of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate schedule. This can then be passed as the learning rate for the optimizer.\n",
    "lrate = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=0.01, decay_steps=1000, decay_rate=0.8)\n",
    "\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=lrate)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fitting the Model</h1>\n",
    "\n",
    "Now, we will fit the RNN to the training data and observe its performance on the validationd data. As the training progresses, we will print out the performance metrics for each epoch to observe the learning process. You can try improving the model performance by changing the hyperparameters and comparing the training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the RNN.\n",
    "history = model.fit(X_train_3D_posed, y_train_onehot, batch_size=16, epochs=50, verbose=1, validation_data=(X_val_3D_posed, y_val_onehot)) # 80% training / 10% validation\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plotting the Accuracy Curves</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracies vs. epochs for the latest loop iteration.\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('RNN_RAVDESS')\n",
    "plt.grid()\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plotting the Loss Curves</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses vs. epochs for the latest loop iteration.\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('RNN_RAVDESS')\n",
    "plt.grid()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluating the Model on Test Set</h1>\n",
    "\n",
    "After being satisfied with the hyperparameter values, we can see how our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`.\n",
    "results = model.evaluate(X_test_3D_posed, y_test_onehot, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving the Model</h1>\n",
    "\n",
    "The final step is to save the model as a separate file so that it can later be imported into the deployment code. Once you run the final cell, three new files should be generated in the directory where you have this notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as an h5 file.\n",
    "model.save('RNN_RAVDESS.h5')\n",
    "\n",
    "# Save mean and standard deviation arrays of features to npy files for standardizing data in other files!\n",
    "np.save('mean_X.npy', mean_X)\n",
    "np.save('std_X.npy', std_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
